\documentclass[]{interact}
\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
\usepackage[caption=false]{subfig}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required
%\usepackage[doublespacing]{setspace}% To produce a `double spaced' document if required
%\setlength\parindent{24pt}% To increase paragraph indentation when line spacing is doubled

\usepackage[numbers,sort&compress]{natbib}% Citation support using natbib.sty
\bibpunct[, ]{[}{]}{,}{n}{,}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty
\makeatletter% @ becomes a letter
\def\NAT@def@citea{\def\@citea{\NAT@separator}}% Suppress spaces between citations using natbib.sty
\makeatother% @ becomes a symbol again

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[ruled,vlined, linesnumbered]{algorithm2e}
\usepackage[english]{babel}
\usepackage[nottoc]{tocbibind}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\hypersetup{colorlinks=true, citecolor=black, linkcolor=., urlcolor=cyan}
\graphicspath{{../plots/}}

% Custom commands / shortcuts
\providecommand{\sign}{\textrm{sign}}
\providecommand{\pb}[1]{\textcolor{red}{#1}}
\providecommand{\lam}{\lambda}
\newcommand{\quotes}[1]{`#1'}


\title{Adaptive Hybrid Screening for Efficient Lasso Optimization}

\author{Word count: 8899.}

  

\date{}

\begin{document}

\maketitle


\begin{abstract}
Lasso type models are a popular approach for analyzing high-dimensional data. The size of modern data sets can be quite large, so developing efficient algorithms is important. Feature screening techniques have proven to be effective at increasing efficiency, as they allow for considerable dimension reduction during the optimization process. In this paper, we develop an adaptive hybrid screening framework where screening is carried out adaptively along the path of tuning parameter values, reusing previous solutions to reduce heavy screening computations if they fail to significantly reduce dimensionality. We focus on the standard lasso model and sparse logistic model, but the proposed framework is flexible and can be easily extended to different types of lasso models. Through experiments involving a wide variety of simulated and real data sets, we show that the adaptive hybrid methods significantly outperform other state-of-the-art methods, with the greatest speedup occurring in the most challenging scenarios.
\end{abstract}

\begin{keywords}
Lasso; feature Screening; safe screening; solution path; large-scale sparse learning
\end{keywords}

\input{../main}

\renewcommand\bibname{References}
\bibliographystyle{tfnlm}
\bibliography{../ref}

\end{document}
